{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preamble: Package Loading\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import pandas as pd\n",
    "import itertools as iter\n",
    "import os\n",
    "import datetime as dt\n",
    "import json\n",
    "import kernel as kr\n",
    "import psc_sumdisp as psd \n",
    "# Preamble working directory retreival\n",
    "wkng_folder = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Estimator With Only ScikitLearn Lasso</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp = data_pan\n",
    "# di = data_inst\n",
    "# de = data_err\n",
    "\n",
    "# dep_nm = inpt['en_nm']\n",
    "# ex_nm = inpt['ex_nm']\n",
    "# n_exo = inpt['n_exo']\n",
    "# ins_nm = list(di.columns)[1:]\n",
    "# adep_nm = [ 0 for i in range(len(dep_nm))]\n",
    "# epsil = 0.05\n",
    "# ain_cf = [ 0 for i in range(len(dep_nm))]\n",
    "# ain_cf_rm = [ 0 for i in range(len(dep_nm))]\n",
    "# excf1 = []\n",
    "\n",
    "# for g in range(len(ex_nm)):\n",
    "#     excf1 = []\n",
    "#     for k in range(inpt['ncs']):\n",
    "#         dsl = dp.loc[dp['crs']==k+1,['t'] + [dep_nm[g]] + ex_nm]\n",
    "#         dsl = pd.merge(dsl,di,how =\"inner\", on='t')\n",
    "#         lin_reg = linear_model.LinearRegression()\n",
    "#         lin_reg.fit(dsl.loc[:,ex_nm+ins_nm].values,dsl.loc[:,dep_nm[g]].values.reshape(dsl.shape[0],1))\n",
    "#         excf1.append([lin_reg.coef_[0][i] for i in range(inpt['n_exo'])])\n",
    "\n",
    "#     incf = [0 for i in range(inpt['t_inst'])]    \n",
    "#     excf = [np.mean([excf1[i][j] for i in range(len(excf1))] ) for j in range(n_exo)]\n",
    "\n",
    "#     adep_nm[g] = ''.join(['a',dep_nm[g]])\n",
    "#     dp[adep_nm[g]] = (dp.loc[:,dep_nm[g]].values.reshape(dp.shape[0],1)\n",
    "#                      -dp.loc[:,ex_nm].values.dot(np.array(excf).reshape(inpt['n_exo'],1)))\n",
    "    \n",
    "#     ain_cf1= []\n",
    "#     for k in range(inpt['ncs']):\n",
    "#         ds2 = dp.loc[dp['crs']==k+1,['t'] + [adep_nm[g]] ]\n",
    "#         ds2 = pd.merge(ds2,data_inst,how =\"inner\", on='t')\n",
    "#         lasso_reg = linear_model.Lasso(alpha = 0.4)\n",
    "#         lasso_reg.fit(ds2.loc[:,ins_nm].values,ds2.loc[:,adep_nm[g]].values.reshape(ds2.shape[0],1))\n",
    "#         ain_cf1.append(list(lasso_reg.coef_))\n",
    "\n",
    "#     ain_cf[g] = excf\n",
    "#     for j in  range(len(ain_cf1[0])): \n",
    "#         a = [ain_cf1[i][j] for i in range(len(ain_cf1)) if np.abs(ain_cf1[i][j]) > epsil]\n",
    "#         if not a:\n",
    "#             ain_cf[g].append(0)\n",
    "#         else:\n",
    "#             ain_cf[g].append(np.mean(a))    \n",
    "\n",
    "#     ain_cf_rm[g] = [[1,1] + [int(np.abs(ain_cf1[j][i])>epsil) \n",
    "#                             for i in range(len(ain_cf1[0]))] \n",
    "#                             for j in range(len(ain_cf1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ain_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(ain_cf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2 Required Functions </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.1 OLS function </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols(df,inpt):\n",
    "    \"\"\"\n",
    "INPUTS\n",
    "df                (pandas df) Data Frame with all regressors\n",
    "inpt              (dict) Dictionary with the following\n",
    "  inpt['dep']     (string) Name of dependent variable contained in df\n",
    "  inpt['reg']     (list of strings) names of regressors in df \n",
    "  inpt['cons']    (0,1) Indicator for whether a constant should be included\n",
    "\n",
    "OUTPUTS \n",
    "out               (list of lists) List of the following\n",
    "  out[0]          (list) Estimated coefficients\n",
    "  out[1]          (list) Residuals\n",
    "  out[2]          (list) Estimated conditional expectation\n",
    "    \"\"\"\n",
    "    # Extracting input variables\n",
    "    dep = inpt['dep']\n",
    "    reg = inpt['reg']\n",
    "    cons = inpt['cons']\n",
    "    # Determining length of df (number of obs)\n",
    "    n = df.shape[0]\n",
    "    # Extracting Dependent Variable from df\n",
    "    Y = df.loc[:,dep].values.reshape(n,1)\n",
    "    # Extracting Regressors from df\n",
    "    if len(reg) == 1:\n",
    "        X = df.loc[:,reg].values.reshape(n,1)\n",
    "    elif len(reg) > 1: \n",
    "        X = df.loc[:,reg].values\n",
    "    # Adding column of ones if a constant is included\n",
    "    if cons == 1: \n",
    "        X = np.hstack((np.ones((n,1)),X))\n",
    "    # Estimated regression coefficients\n",
    "    alpha = np.linalg.inv(X.T.dot(X)).dot(X.T.dot(Y))\n",
    "    # Estimated Conditional Expectation\n",
    "    Yhat = X.dot(alpha)\n",
    "    # Residuals of the regression\n",
    "    res = Y - X.dot(alpha)\n",
    "    # Constructing output list of lists\n",
    "    out = [alpha.T.tolist()[0],res.T.tolist()[0],Yhat.T.tolist()[0]]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.2 Panel Data Estimator </h3>\n",
    "\n",
    "This function will perform lasso estimation based on the value of inpt['lasso']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2.4 Lasso Panel Estimator </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pan_lasso(l_dp,l_inpt):\n",
    "    \"\"\"\n",
    "INPUTS\n",
    "l_dp                 (df) all panel regression variables \n",
    "l_inpt               (dict) Containing the following elements\n",
    "  l_inpt['dep']        (str) name of dependent variable\n",
    "  l_inpt['ex_nm']      (str) name of all exogenous variables\n",
    "  l_inpt['ins_nm']     (str) name of all instruments\n",
    "  l_inpt['alph']       (flt) lasso penalty parameter\n",
    "  l_inpt['ncs']        (int) number of cross sections\n",
    "  l_inpt['epsil']      (flt) threshold for averaging \"non zero\" coefficients\n",
    "  \n",
    "OUTPUTS\n",
    "out            (lst) with the following elements\n",
    " out[0]        (lst) Estimated coefficients\n",
    " out[1]        (lst) containing the following elements\n",
    "   out[1][j]   (lst) binary vector indicating the non zero ceofficients for each crs\n",
    "    \"\"\"\n",
    "    \n",
    "# Extracting variables from input dictionary\n",
    "    l_dep_nm = l_inpt['dep']\n",
    "    l_ex_nm = l_inpt['ex_nm']\n",
    "    l_ins_nm = l_inpt['ins_nm']\n",
    "    l_alph = l_inpt['alph']\n",
    "    l_epsil = l_inpt['epsil']\n",
    "    n_exo = len(l_ex_nm)\n",
    "    ncs = l_inpt['ncs']\n",
    "    t_inst = len(l_ins_nm)\n",
    "    # Initializing the coefficient list\n",
    "    excf1 = []\n",
    "\n",
    "    # Estimating the coefficients on the exogenous regressors\n",
    "    for k in range(inpt['ncs']):\n",
    "        # Extracting the kth cross sections data \n",
    "        dsl = l_dp.loc[l_dp['crs']==k+1,:]\n",
    "        #Initializing the regression model\n",
    "        lin_reg = linear_model.LinearRegression()\n",
    "        #Fitting the regression model\n",
    "        lin_reg.fit(dsl.loc[:,l_ex_nm+l_ins_nm].values,\n",
    "                    dsl.loc[:,l_dep_nm].values.reshape(dsl.shape[0],1))\n",
    "        # Appending the est coeff for exogenous regressors to coeff list\n",
    "        excf1.append([lin_reg.coef_[0][i] for i in range(n_exo)])\n",
    "\n",
    "    # Averaging coefficient values over cross sections  \n",
    "    excf = [np.mean([excf1[i][j] for i in range(len(excf1))]) for j in range(n_exo)]\n",
    "    # Generating the name of the modified dependent variable\n",
    "    adep_nm = ''.join(['a',l_dep_nm])\n",
    "    # Generating the modified dependent variable\n",
    "    l_dp[adep_nm] = (l_dp.loc[:,l_dep_nm].values.reshape(l_dp.shape[0],1)\n",
    "                     -l_dp.loc[:,l_ex_nm].values.dot(np.array(excf).reshape(n_exo,1)))\n",
    "\n",
    "    # Initialzing the list of estimated lasso coefficients                 \n",
    "    ain_cf1 = []\n",
    "    for k in range(ncs): \n",
    "        # Extracting modified dep and indep regressor for crs k \n",
    "        ds2 = l_dp.loc[l_dp['crs']==k+1,:]\n",
    "        # Initializing lasso regression model\n",
    "        lasso_reg = linear_model.Lasso(alpha = l_inpt['alph'])\n",
    "        # Fitting the regression model\n",
    "        lasso_reg.fit(ds2.loc[:,l_ins_nm].values,\n",
    "                      ds2.loc[:,adep_nm].values.reshape(ds2.shape[0],1))\n",
    "        # Appending lasso coefficient to list\n",
    "        ain_cf1.append(list(lasso_reg.coef_))\n",
    "\n",
    "    # Initializing set of estiamated coeff with those one the exogenous variables\n",
    "    ain_cf = excf\n",
    "    # generating the final averged values of each coefficient\n",
    "    for j in range(len(ain_cf1[0])): \n",
    "        # Collecting all coeff estimated on jth inst greater than threshold l_epsil\n",
    "        a = [ain_cf1[i][j] for i in range(len(ain_cf1)) if np.abs(ain_cf1[i][j]) > l_epsil]\n",
    "        if not a:\n",
    "            # If a is an empty list inst not selected in any crs so append a zero\n",
    "            ain_cf.append(0)\n",
    "        else:\n",
    "            # Averging if a is non empty\n",
    "            ain_cf.append(np.mean(a))    \n",
    "\n",
    "    # Generating a list of lists where ain_cf_rm[j][i]=1 if the |coeff| on the ith inst\n",
    "    # for the jth cross section is greater than l_epsil\n",
    "    ain_cf_rm = [[1,1] + [int(np.abs(ain_cf1[j][i])>l_epsil) \n",
    "                            for i in range(len(ain_cf1[0]))] \n",
    "                            for j in range(len(ain_cf1))]\n",
    "    # Function output\n",
    "    out = [ain_cf, ain_cf_rm]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 3 Setup and Functions Call </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def panel_fe(dp_in,di_in,inpt):\n",
    "    \"\"\"\n",
    "INPUTS\n",
    "dp_in                     (pandas df) df with dependent var. and all exogenous regs\n",
    "di_in                     (pandas df) df with all instruments\n",
    "inpt                      (dict) Dictionary with the following\n",
    "  inpt['dep']               (string) Name of dependent variable contained in dp\n",
    "  inpt['reg']               (list of strings) names of exogenous regressors\n",
    "  inpt['cin']               (string) name of crossection index in dp\n",
    "  inpt['tin']               (string) name of time index in dp\n",
    "  inpt['ncs']               (int) number of crossections\n",
    "  inpt['alph']              (flt) penalty value for lasso estimation\n",
    "  inpt['epsil']             (flt)  threshold for averaging \"non zero\" coefficients\n",
    "  inpt['lasso']             (int) indicator for whether subset selection with lasso is done\n",
    "  inpt['in_nm']             (list of lists of strings) with the following components\n",
    "    input['in_nm'][i-1]       (list of names) names of instruments relevant to crs i \n",
    "  \n",
    "\n",
    "OUTPUTS \n",
    "out               (list of lists) List of the following\n",
    "  out[0]          (list) Estimated coefficients\n",
    "  out[1]          (list) list of all relevant instrument\n",
    "  out[2]          (list) Estimated error terms Vi_j\n",
    "  \"\"\"\n",
    "\n",
    "    ## Extracting Variables from inpt dictionary\n",
    "    dep = inpt['dep']\n",
    "    reg = inpt['reg']\n",
    "    in_nm = inpt['in_nm']\n",
    "    cin = inpt['cin']\n",
    "    tin = inpt['tin']\n",
    "    ncs = inpt['ncs']\n",
    "    lasso = inpt['lasso']\n",
    "    di  = di_in\n",
    "    dp  = dp_in\n",
    "\n",
    "    ## Constructing a df of all instrument relevant to at least 1 crossection\n",
    "    # Initializing the set of all included instruments as the 1st set relevant inst\n",
    "    inc = set(in_nm[0])\n",
    "    # Collecting rest of relevant instruments\n",
    "    for i in range(len(in_nm)):\n",
    "        # Union of inc and ith set of relevant instruments\n",
    "        inc = inc|set(in_nm[i])\n",
    "    # All included Instruments listed in order index order\n",
    "    inc = [''.join(['W',str(i)]) for i in range(1,di.shape[1]) if ''.join(['W',str(i)]) in inc]\n",
    "    # df with time index and all included instruments\n",
    "    di_inc = di.loc[:,[tin] + inc]\n",
    "\n",
    "    # List of logical vectors (as list) of which instruments in inc are relevant to ith crs\n",
    "    in_vec = [[ 1 if inc[i] in in_nm[j] else 0 for i in range(len(inc))]\n",
    "                  for j in range(ncs)]\n",
    "\n",
    "    # First differenced included instrument df\n",
    "    Di = di_inc.loc[:,[tin]]\n",
    "    for j in range(0,len(inc)):\n",
    "        # Adding D to name of jth instrument in inc\n",
    "        D_nm = ''.join(['D', di_inc.columns[j+1]])\n",
    "        # First difference of jth instrument in inc\n",
    "        Di[D_nm] = (di_inc.loc[:,di_inc.columns[j+1]].values \n",
    "                    - di_inc.loc[:,di_inc.columns[j+1]].shift(1).values)\n",
    "\n",
    "    ## Constructing Panel Version of relevant instrument data\n",
    "    for i in range(ncs):\n",
    "        # Initializing differenced panel template df\n",
    "        a1 = Di.loc[:,tin].copy()\n",
    "        # Adding the crossection variable\n",
    "        a1 = pd.concat([a1,pd.DataFrame(np.ones((di_inc.shape[0],1))*(i+1)\n",
    "                                        ,columns = [cin])],axis = 1)\n",
    "        # Initializing the panel template df\n",
    "        b1 = a1\n",
    "        # Product of Di with in_vec[i-1] s.t. inst. not relevant to i are zero \n",
    "        a2 = pd.DataFrame(Di.iloc[:,1:].values.dot(np.diag(in_vec[i]))\n",
    "                          ,columns = Di.columns[1:])\n",
    "        # Product of di_inc with in_vec[i-1] s.t. inst. not relevant to i are zero\n",
    "        b2 = pd.DataFrame(di_inc.iloc[:,1:].values.dot(np.diag(in_vec[i]))\n",
    "                          ,columns = di_inc.columns[1:])\n",
    "        # Concatenating a2 onto panel template adding [cin] and [tin]\n",
    "        a2 = pd.concat([a1,a2],axis = 1)\n",
    "        # Concatenating b2 onto panel template adding [cin] and [tin]\n",
    "        b2 = pd.concat([b1,b2],axis = 1)\n",
    "        if i == 0:\n",
    "            # if  i = 0 initialize final differenced panel df\n",
    "            Ddi_pan = a2.iloc[1:,:]\n",
    "            # if i = 0 initialize final panel df\n",
    "            di_pan = b2\n",
    "        elif i > 0: \n",
    "            # if i > 0 add ith crosssection rows onto final\n",
    "            Ddi_pan = pd.concat([Ddi_pan,a2.iloc[1:,:]], axis = 0)\n",
    "            # if i > 0 add ith crosssection rows onto final\n",
    "            di_pan =  pd.concat([di_pan,b2], axis = 0)\n",
    "\n",
    "    ## First Difference dependent and exogenous regressor matrix..\n",
    "    for i in range(1,ncs+1):\n",
    "        # Initializing panle template df\n",
    "        c1 = dp.loc[dp[cin]== i,[cin]+[tin]].copy() \n",
    "        # First differencing al relevant variables for i crs\n",
    "        for j in [inpt['dep']] + inpt['reg']:\n",
    "            c1[''.join(['D',j])] = (dp.loc[dp[cin]== i,j].values \n",
    "                        - dp.loc[dp[cin]== i,j].shift(1).values)\n",
    "        if i == 1:\n",
    "            # If i = 1 initialize final panel df\n",
    "            c2 = c1.iloc[1:,:]  \n",
    "        elif i > 1:\n",
    "            # If i > 1 add onto final panel df\n",
    "            c2 = pd.concat([c2,c1.iloc[1:,:]],axis = 0)\n",
    "\n",
    "    ## OLS estimation\n",
    "    # Merging all differenced panel df's together\n",
    "    Ddi_pan = pd.merge(c2,Ddi_pan,on=[cin,tin],how = 'inner')\n",
    "    # List of all regressor names in Ddi_pan for use in ols()\n",
    "    Dregs = ([''.join(['D',reg[i]]) for i in range(len(reg))] \n",
    "            + [''.join(['D',inc[i]]) for i in range(len(inc))])\n",
    "\n",
    "    if lasso == 0:\n",
    "        # Initializing ols object\n",
    "        ols_reg =linear_model.LinearRegression()\n",
    "        # Fitting the OLS regression\n",
    "        ols_reg.fit(Ddi_pan.drop([cin]+[tin]+[''.join(['D',dep])],axis=1),\n",
    "                    Ddi_pan.loc[:,''.join(['D',dep])])\n",
    "        # Extracting estimated regression coefficients\n",
    "        ols_out = ols_reg.coef_.tolist()\n",
    "        # Initializing the ceofficient vector with zero's for regressors irrelevant to all crs\n",
    "        ex_cf = ols_out[:len(reg)]\n",
    "        # List of ex regressor column names in di\n",
    "        fins_nm = di_in.columns.tolist()[len(reg)-1:]\n",
    "        fregs = reg + fins_nm\n",
    "        for i in range(len(fins_nm)):\n",
    "            if inc.count(fins_nm[i]) > 0:\n",
    "                # If the ith inst in di is in inc append the corr. coefficient to ex_cf\n",
    "                ex_cf.append(ols_out[inc.index(fins_nm[i])+len(reg)])\n",
    "            elif inc.count(fins_nm[i])==0:\n",
    "                # If the ith inst in di is not in inc append a zero\n",
    "                ex_cf.append(0)  \n",
    "        # List of lists of indicator of relevant ex and inst to each cross section      \n",
    "        rev_cf = [[1]*len(reg) + [in_nm[i].count(fins_nm[j]) \n",
    "                                  for j in range(len(fins_nm))] \n",
    "                                  for i in range(len(in_nm))]\n",
    "\n",
    "    elif lasso == 1:\n",
    "        # Input dictionary for Lasso Estimation\n",
    "        l_inpt = {'dep': ''.join(['D',dep]),\n",
    "                      'ex_nm': [''.join(['D',reg[i]]) for i in range(len(reg))],\n",
    "                      'ins_nm': [''.join(['D',inc[i]]) for i in range(len(inc))],\n",
    "                      'alph': inpt['alph'],'ncs':inpt['ncs'],'epsil':inpt['epsil']\n",
    "                     }\n",
    "        # Estimation by panel lasso\n",
    "        out = pan_lasso(Ddi_pan,l_inpt)\n",
    "        # Extracting estimated coefficients\n",
    "        ex_cf = np.array(out[0]).reshape(len(out[0]),1)\n",
    "        # Relevant instrument matrix\n",
    "        rev_cf = out[1]\n",
    "\n",
    "    # Constucting a panel df of esitmated errors Vj,i\n",
    "    for i in range(1,ncs+1):\n",
    "        # np.array of dep variable values for ith crs\n",
    "        d1 = dp.loc[dp[cin] == i,[dep]].values\n",
    "        # df of exogenous regressor values for ith crs\n",
    "        d21 = dp.loc[dp[cin] == i ,[tin]+reg]\n",
    "        # merging d21 and d22 making a df with all RHS regressors \n",
    "        d23 = pd.merge(d21,di,on = [tin], how = 'inner')\n",
    "        # d2\n",
    "        d2 = d23.drop(tin,axis=1).values.dot(np.diag(rev_cf[i-1])).dot(ex_cf)\n",
    "        # Residual of time varying component \n",
    "        d3 = d1.reshape(d1.shape[0],1) - d2.reshape(d2.shape[0],1)\n",
    "        # Centered residula of time varying component\n",
    "        d3 = d3 - np.mean(d3)\n",
    "        if i == 1:\n",
    "            # if i = 1 initialize panel df\n",
    "            p_res = [list(d3.T[0])]\n",
    "        elif i > 1:\n",
    "            # if i > 1 add onto p_res\n",
    "            p_res.append(list(d3.T[0]))\n",
    "\n",
    "    # Output of the function\n",
    "    pan_out = [ex_cf,inc , p_res, rev_cf]\n",
    "\n",
    "    return pan_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_subs(k,ntp,ncs):\n",
    "    \"\"\"\n",
    "INPUTS\n",
    " k       (int) number of partition memebers\n",
    " ntp     (int) number of time periods\n",
    "\n",
    "OUTPUTS\n",
    " out                    (list) containing the following elements\n",
    "   out[0]               (list of tuples) index numbers for instrument partitions\n",
    "     out[0][i]          (tuples of list) ith instrument partition\n",
    "         out[0][i][0]   (list) of row numbers in the ith part. training set for instruments\n",
    "         out[0][i][1]   (list) of row numbers in the ith part. test set for instruments\n",
    "   out[1]               (list of tuples) index numbers for panel data partitions\n",
    "     out[1][i]          (tuples of list) ith panel data partition\n",
    "         out[1][i][0]   (list) of row numbers in the ith part. training set for panel data\n",
    "         out[1][i][1]   (list) of row numbers in the ith part. test set for panel data\n",
    "    \"\"\"\n",
    "    # List of row index numbers for each cross section\n",
    "    a0 = [i for i in range(ntp)]\n",
    "    # Length of the first k-1 partition list\n",
    "    n_sl = int(np.floor(ntp)/k)\n",
    "    # Generating the k-1 partitions as a lists of disjoint exhaustive lists \n",
    "    k_grp = [[a0.pop(np.random.randint(1,ntp-i-j*n_sl)) for i in range(n_sl)] \n",
    "                                                                for j in range(k-1)]\n",
    "    # Adding in the last partition\n",
    "    k_grp.append(a0)\n",
    "    # Inintializing list of train / test tuples \n",
    "    in_indx = []\n",
    "    pan_indx = []\n",
    "    for i in range(k):\n",
    "        # Initializing the ith train list\n",
    "        a2 = []\n",
    "        # Initializing the list of partitions whose union is a training set\n",
    "        a3 = list(range(k))\n",
    "        # Removing the test set index\n",
    "        del a3[i]\n",
    "        for j in a3:\n",
    "            # Taking the union of all training set partition lists\n",
    "            a2 = sorted(a2 + k_grp[j])\n",
    "        # Creating the ith (training,test) tuple\n",
    "        a4 = (a2,sorted(k_grp[i]))\n",
    "        # Appending to full list\n",
    "        in_indx.append(a4)\n",
    "        a5 = a2\n",
    "        a6 = sorted(k_grp[i])\n",
    "        for j in range(1,ncs):\n",
    "            a5 = a5 + (np.array(a2)+j*ntp).tolist()\n",
    "            a6 = a6 + (np.array(sorted(k_grp[i]))+j*ntp).tolist()\n",
    "        a7 = (a5,a6)\n",
    "        pan_indx.append(a7)\n",
    "        \n",
    "    return([in_indx,pan_indx])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrg_dff(dp_in,di_in,inpt):\n",
    "    \"\"\"\n",
    "INPUTS \n",
    "  dp_in      (df) panel dataframe \n",
    "  di_in      (df) instruments dataframe\n",
    "  inpt       (dict) Containing the following elements\n",
    "    inpt['tin']    (str) time index column name\n",
    "    inpt['cin']    (str) cross section index column name\n",
    "    inpt['ncs']    (int) number of cross sections\n",
    "    \n",
    "OUTPUTS\n",
    "  out[0]             (df) dp_in and di_in merged on tin for each cin and 1st differenced\n",
    "  out[1]             (df) dp_in and di_in merged on tin for each cin \n",
    "    \"\"\"\n",
    "    # Extracting variables from input dictionary\n",
    "    tin = inpt['tin']\n",
    "    cin = inpt['cin']\n",
    "    ncs = inpt['ncs']\n",
    "    \n",
    "    # Looping over each cross section\n",
    "    for i in range(ncs):\n",
    "        # Merging panel and instrument df on tin for ith cross section\n",
    "        b1 = pd.merge(dp_in.loc[dp_in[cin]== i+1,:],di_in,how = 'inner', on = tin)\n",
    "        # Initializing the temp difference matrix \n",
    "        b2 = b1.loc[1:,[tin]+[cin]] \n",
    "        # Looping over all the column names in b1\n",
    "        for nm in b1.columns[2:].tolist():\n",
    "            # 1st Differencing nm column of b1\n",
    "            b2[''.join(['D',nm])] = (b1.loc[:,nm].values - b1.loc[:,nm].shift(1).values)[1:]\n",
    "        if i == 0:\n",
    "            # Initializing final matrix out\n",
    "            out1 = b2\n",
    "            out2 = b1\n",
    "        elif i > 0:\n",
    "            # Concatenating b2 to out\n",
    "            out1 = pd.concat([out1,b2],axis =0)\n",
    "            out2 = pd.concat([out2,b1],axis =0)\n",
    "            out = [out1 , out2]\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.1 Data Loading </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = 'pscdata_7_17_1126.json'\n",
    "data_file = '/Users/ericpenner/Google_Drive/Research/pan_sel_cntrl/data'\n",
    "input_file_full = ''.join([data_file,'/',input_filename])\n",
    "with open(input_file_full) as f_obj: \n",
    "    pscdata = json.load(f_obj)\n",
    "inpt = pscdata[0][0].copy()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.2 Input Dictionary Setup </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicator for  whether in this run the subset of instrument relvant to each crs is known.\n",
    "inpt['kwnsub'] = 0\n",
    "\n",
    "# Indicator for whether residuals are observed\n",
    "inpt['orcl'] = 0\n",
    "inpt['lasso'] = 0\n",
    "inpt['dep'] = inpt['en_nm'][0]\n",
    "inpt['reg'] = inpt['ex_nm']\n",
    "inpt['alph'] = 0.4\n",
    "inpt['epsil'] = 0.09\n",
    "\n",
    "# List of list with the names of the relevant instruments for each crossection\n",
    "in_nm=[]\n",
    "for i in range(inpt['ncs']):\n",
    "    # If the subset is known then list of relevant inst. for each crs is supplied to estimator\n",
    "    if inpt['kwnsub'] == 1:\n",
    "        a=[ True if pscdata[0][1]['coeff'][0][i][k]!=0 else False \n",
    "            for k in range(inpt['n_exo'],inpt['n_exo']+inpt['t_inst'])]\n",
    "        in_nm.append(np.array(pscdata[0][1]['Dins_nms'][1:])[a].tolist())\n",
    "    # If the subset is unknown then list of all inst. will be supplied to est. for each crs\n",
    "    else:\n",
    "        in_nm.append(pscdata[0][1]['Dins_nms'][1:])\n",
    "        \n",
    "inpt['in_nm'] = in_nm\n",
    "inpt_l = inpt.copy()\n",
    "inpt_l['lasso'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3.3 Data Set Extraction and Function Call </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=100\n",
    "data_err = pd.DataFrame(pscdata[k][0]['err_df'], columns = pscdata[0][1]['Derr_nms'])  \n",
    "data_inst = pd.DataFrame(pscdata[k][0]['inst_df'], columns = pscdata[0][1]['Dins_nms'])\n",
    "data_pan = pd.DataFrame(pscdata[k][0]['prim_df'], columns = pscdata[0][1]['Dlng_nms'])\n",
    "\n",
    "m_inpt = {'tin' :inpt['tin'], 'cin' : inpt['cin'] , 'ncs': inpt['ncs']}\n",
    "data_pan_trns = mrg_dff(data_pan,data_inst,m_inpt)\n",
    "data_pan_mrdf = data_pan_trns[0]\n",
    "data_pan_mr   = data_pan_trns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_ls = {}\n",
    "inpt_ls['dep'] = 'DZ1,1'\n",
    "inpt_ls['odep'] = 'Z1,1'\n",
    "inpt_ls['ex_nm'] = [''.join(['DZ2,',str(i)]) for i in range(1,inpt['n_exo']+1)]\n",
    "inpt_ls['oex_nm'] = [''.join(['Z2,',str(i)]) for i in range(1,inpt['n_exo']+1)]\n",
    "inpt_ls['ins_nm'] = [''.join(['DW',str(i)]) for i in range(1,inpt['t_inst']+1)]\n",
    "inpt_ls['oins_nm'] = [''.join(['W',str(i)]) for i in range(1,inpt['t_inst']+1)]\n",
    "inpt_ls['alph'] = 0.45\n",
    "inpt_ls['epsil'] = 0.1\n",
    "inpt_ls['cin'] = inpt['cin']\n",
    "inpt_ls['tin'] = inpt['tin']\n",
    "inpt_ls['n_alphs'] = 20\n",
    "inpt_ls['n_parts'] = 4\n",
    "inpt_ls['ntp'] = inpt['ntp']\n",
    "inpt_ls['ncs'] = inpt['ncs']\n",
    "inpt_ls['cv'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pan_lasso_cv(data_pan_mr,data_pan_mrdf,inpt_ls):\n",
    "    \n",
    "    \"\"\"\n",
    "INPUTS\n",
    "  data_pan_mr            (df) panel where crs regs are merged with insts\n",
    "  data_pan_mrdf          (df) panel where crs regs are merged with insts and 1st differenced\n",
    "  inpt_ls                (dict) of the following elements\n",
    "    inpt_ls['cv']        (int) indicator for whether cross validation is done\n",
    "    inpt_ls['dep']       (str) names of differenced dependent variable in lasso reg\n",
    "    inpt_ls['odep']      (str) names of non differenced dependent variable\n",
    "    inpt_ls['ex_nm']     (lst) names of differenced exogenous variables\n",
    "    inpt_ls['oex_nm']    (lst) names of non differenced exogenous variables\n",
    "    inpt_ls['ins_nm']    (lst) names of differenced instruments\n",
    "    inpt_ls['oins_nm']   (lst) names of non difference instruments\n",
    "    inpt_ls['alph']      (flt) initial alpha tuning parameter\n",
    "    inpt_ls['epsil']     (flt) threshold for averaging \"non zero\" coefficients\n",
    "    inpt_ls['cin']       (str) name of crs section variable\n",
    "    inpt_ls['tin']       (str) name of time variable\n",
    "    inpt_ls['n_alphs']   (int) number of different alphas tried\n",
    "    inpt_ls['n_parts']   (int) number of partition elements \n",
    "    inpt_ls['ntp']       (int) number of time periods\n",
    "    inpt_ls['ncs']       (int) number of cross sections\n",
    "\n",
    "OUPUTS\n",
    "    out             (lst) with the following elements\n",
    "      out[0]        (lst) Estimated coefficients\n",
    "      out[1]        (lst) containing the following elements\n",
    "        out[1][j]   (lst) binary vector indicating the non zero ceofficients for each crs\n",
    "      out[2]        (lst) list of mean meansquared errors \n",
    "      out[3]        (lst) cross validated alpha tuning parameter\n",
    "    \"\"\"\n",
    "                    \n",
    "    #Extracting info from dictionary\n",
    "    n_alphs = inpt_ls['n_alphs']\n",
    "    oins_nm = inpt_ls['oins_nm']\n",
    "    oex_nm = inpt_ls['oex_nm']\n",
    "    odep = inpt_ls['odep']\n",
    "    n_parts = inpt_ls['n_parts']\n",
    "    n_alphs = inpt_ls['n_alphs'] \n",
    "    cin = inpt_ls['cin']\n",
    "    tin = inpt_ls['tin']\n",
    "    ncs = inpt_ls['ncs']\n",
    "    ntp = inpt_ls['ntp'] \n",
    "    cv = inpt_ls['cv']\n",
    "\n",
    "    if cv == 0:\n",
    "        # Estimating lasso regression with orginal input alpha\n",
    "        ls_soln = pan_lasso(data_pan_mrdf,inpt_ls)\n",
    "        out = ls_soln + ['none'] + ['none']\n",
    "\n",
    "    elif cv == 1:  \n",
    "        # Generating partitions\n",
    "        indx = k_subs(n_parts,ntp-1,ncs)\n",
    "\n",
    "        # Initializing carrier lists\n",
    "        all_msr = []\n",
    "        trl_alph = []\n",
    "\n",
    "        # For each value of lasso tuning parameter\n",
    "        for k in range(5,n_alphs+6):\n",
    "            # Initializing mean squared error list for each partition\n",
    "            msr = []\n",
    "            # Setting the value of the lasso tuning parameter\n",
    "            inpt_ls['alph'] = k/n_alphs\n",
    "            # Appending the current lasso tuning parameter\n",
    "            trl_alph.append(k/n_alphs)\n",
    "            # For each of the training testing set combinations\n",
    "            for part in range(n_parts):\n",
    "                # Merged and differenced training set\n",
    "                trn_mrdf = data_pan_mrdf.iloc[indx[1][part][0],:].copy()\n",
    "                # Merged and differenced testing set\n",
    "                tst_mrdf = data_pan_mrdf.iloc[indx[1][part][1],:].copy()\n",
    "                # Merged only testing set\n",
    "                tst_mr = data_pan_mr.iloc[indx[1][part][1],:].copy()\n",
    "                # lasso estimation on training data set\n",
    "                lcf = pan_lasso(trn_mrdf,inpt_ls)\n",
    "                # Initializng list of allresiduals for each cross section \n",
    "                all_res = []\n",
    "                # for each cross section\n",
    "                for i in range(ncs):\n",
    "                    # Extracting the un difference test regressor matrix for crs i\n",
    "                    c1 = tst_mr.loc[tst_mr[cin]==i+1, oex_nm + oins_nm ].values\n",
    "                    # Creating the diagonal selection matrix for crs i\n",
    "                    c2 = np.diag(lcf[1][i])\n",
    "                    # Reshaping Estimated lasso coefficient matrix\n",
    "                    c3 = np.array(lcf[0]).reshape(len(oex_nm + oins_nm),1)\n",
    "                    # Computing partial estimated values (no constant term included)\n",
    "                    c4 = c1.dot(c2).dot(c3)\n",
    "                    # Computing non centered residuals (no constant term included)\n",
    "                    res1 = tst_mr.loc[tst_mr[cin]==i+1,odep].values.reshape(len(c4),1) - c4\n",
    "                    # Computing centered squared residuals\n",
    "                    cres = (res1 - np.mean(res1))**2\n",
    "                    # Concatenating sqr residuals of ith cross section to all_res\n",
    "                    all_res = all_res + cres.tolist()\n",
    "                # Appending the mean sqrd residuals for the npart th trn and test set \n",
    "                msr.append(np.mean(all_res))\n",
    "            # Appending the mean of mean sqrd residuals for all partitions   \n",
    "            all_msr.append(np.mean(msr))\n",
    "\n",
    "        # Index of smallest mean msr values\n",
    "        ax = all_msr.index(min(all_msr))\n",
    "        # alpha value that produces smallest mean_msr\n",
    "        cv_alph = trl_alph[ax]\n",
    "\n",
    "        # Running Lasso with cv alpha\n",
    "        inpt_ls['alpha'] = cv_alph\n",
    "        # Estimating lasso regression with cros validated alpha\n",
    "        ls_soln = pan_lasso(data_pan_mrdf,inpt_ls)\n",
    "        out = ls_soln\n",
    "        out.append(all_msr)\n",
    "        out.append(cv_alph)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.9909308494453454,\n",
       "  -1.6301911468671897,\n",
       "  -0.6645609811126933,\n",
       "  -0.6742084982696254,\n",
       "  0.2117072697796479,\n",
       "  0.38894954585279334,\n",
       "  0.09738059227056452,\n",
       "  -0.4990077713403003,\n",
       "  -0.2767514622919783,\n",
       "  0.6661966228575743,\n",
       "  0.2948102744377507,\n",
       "  0.22509961234715714,\n",
       "  0.835933840989816,\n",
       "  -0.5899525334780038,\n",
       "  0.1342343817991136,\n",
       "  0,\n",
       "  0.33254725567232046,\n",
       "  -0.07024602179817724,\n",
       "  -0.5262111025110955,\n",
       "  -0.30795329447596265,\n",
       "  -0.5245828064034782,\n",
       "  0],\n",
       " [[1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "  [1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       "  [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "  [1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "  [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
       "  [1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0]],\n",
       " 'none',\n",
       " 'none']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pan_lasso_cv(data_pan_mr,data_pan_mrdf,inpt_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_l['alph'] = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = panel_fe(data_pan,data_inst,inpt)\n",
    "c_l = panel_fe(data_pan,data_inst,inpt_l)\n",
    "\n",
    "i=1\n",
    "h_c = 1.5\n",
    "ker = 9\n",
    "\n",
    "# V_knw = np.array(c_k[2][i-1])\n",
    "# p_knw = np.linspace(np.min(V_knw),np.max(V_knw),100)\n",
    "# h_knw = h_c*V_unk.shape[0]**(-1/5)*np.std(V_knw)\n",
    "# V_knw_den = kr.mvden(V_knw,p_knw,h_knw,ker)\n",
    "\n",
    "V_unk = np.array(c[2][i])\n",
    "p_unk = np.linspace(np.min(V_unk),np.max(V_unk),100)\n",
    "h_unk = h_c*V_unk.shape[0]**(-1/5)*np.std(V_unk)\n",
    "V_unk_den = kr.mvden(V_unk,p_unk,h_unk,ker)\n",
    "\n",
    "V_lass = np.array(c_l[2][i])\n",
    "p_lass = np.linspace(np.min(V_lass),np.max(V_lass),100)\n",
    "h_lass = h_c*V_lass.shape[0]**(-1/5)*np.std(V_lass)\n",
    "V_lass_den = kr.mvden(V_lass,p_lass,h_lass,ker)\n",
    "\n",
    "V_true = data_err.loc[data_err['crs']==i+1,'V1'].values\n",
    "p_true = np.linspace(np.min(V_true),np.max(V_true),100)\n",
    "h_true = h_c*V_true.shape[0]**(-1/5)*np.std(V_true)\n",
    "V_true_den = kr.mvden(V_true,p_true,h_true,ker) \n",
    "\n",
    "x_lm = [-5,5]\n",
    "y_lm = 1\n",
    "\n",
    "f,ax = plt.subplots()\n",
    "f.set_figheight(7)\n",
    "f.set_figwidth(15)\n",
    "ax.set_xlim((x_lm[0],x_lm[1]))\n",
    "ax.set_ylim((0,y_lm))\n",
    "ax.plot(p_unk,V_unk_den)\n",
    "ax.plot(p_lass,V_lass_den)\n",
    "ax.plot(p_true,V_true_den)\n",
    "ax.legend([\"Unknown\",\"Lasso\",\"True\"])\n",
    "ax.grid(which = 'both')\n",
    "#ax.set_title(''.join(['Distribution of Estimated ',coeff[0].columns[w]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
