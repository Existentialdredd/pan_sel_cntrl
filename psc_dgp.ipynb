{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preamble: Package Loading\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import itertools as iter\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Block Diagonal Matrix Function </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blkdiag(mat,nb):\n",
    "    \"\"\"\n",
    "INPUTS\n",
    "mat     Square Matrix which will form the block in a block diagonal matrix\n",
    "nb      Number of diagonal block in output matrix \n",
    "\n",
    "OUTPUT\n",
    "v       Block diagonal matrix of dimension ( nb*mat.shape[0] x nb*mat.shape[0] )\n",
    "    \"\"\"\n",
    "    # Initializing the varcov matrix for all crosssections\n",
    "    v = np.hstack((mat,np.zeros((mat.shape[0],(nb-1)*(mat.shape[1])))))\n",
    "    # Registry matrix used in following loops\n",
    "    vreg = np.eye(nb-1)\n",
    "    for j in np.arange(nb-1):\n",
    "        # Initializing current block of rows \n",
    "        pv = np.zeros((mat.shape[0],mat.shape[0]))\n",
    "        # Horiz Stacking either zeros or var_err depending on ve_reg[j,i]\n",
    "        for i in np.arange(nb-1):\n",
    "            if vreg[j,i] == 1: # Stack var_err onto pv_err\n",
    "                pv = np.hstack((pv,mat))\n",
    "            if vreg[j,i] == 0: # Stack zeros onto pv_err\n",
    "                pv = np.hstack((pv,np.zeros((mat.shape[0],mat.shape[0]))))\n",
    "        # Vertically stacking block rows on top of one another\n",
    "        v = np.vstack((v,pv))\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Block Diagonal Matrix Function Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blkdiag(np.ones((3,3)),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> DGP Inputs </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a Seed\n",
    "np.random.seed([10])\n",
    "\n",
    "# Number of Time Periods\n",
    "ntp = 10\n",
    "# Number of Cross-Sections\n",
    "ncs = 3\n",
    "# Number of Endogenous Variables in Primary Equation\n",
    "n_end = 2\n",
    "# Number of Endogenous Variables in Primary Equation\n",
    "n_exo = 2\n",
    "# Total Number of Instruments\n",
    "t_inst = 10\n",
    "# Number of Instruments per Crossection\n",
    "c_inst = 3\n",
    "# Indicator for whether to force additive non linear cntrl function. 1 = yes \n",
    "frc = 0\n",
    "\n",
    "# Vector of exog off diagonal covariances i.e. cov(Z2t_l,Z2t_(l+j)) = ex_vpro[j-1]\n",
    "ex_vpro = [0.5]\n",
    "# Vector of inst off diagonal covariances i.e. cov(Wt_l,Wt_(l+j)) = inst_vpro[j-1]\n",
    "inst_vpro = [0.5 , 0.25 ]\n",
    "# Vector of error off diagonal covariances i.e. cov(Wt_l,Wt_(l+j)) = inst_vpro[j-1]\n",
    "err_vpro = [0.8 , 0.36 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> DGP Generation Code </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.8 ms, sys: 173 Âµs, total: 22 ms\n",
      "Wall time: 22.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Collection of all Coefficients on Instruments \n",
    "icoeffs_reg = list(iter.product([-1,1],repeat = c_inst))\n",
    "# Collection of all Coefficients on Exogenous Variables\n",
    "excoeffs_reg = list(iter.product([-1,1],repeat = n_exo))\n",
    "# Registry of instrument assignments\n",
    "insts_reg = list(iter.combinations(np.arange(1,t_inst+1),c_inst))\n",
    "\n",
    "# List of which instruments (col #'s) are used for each crossection \n",
    "icr = [insts_reg[np.random.randint(len(insts_reg))] for i in range(ncs)]\n",
    "\n",
    "# All permutation of combinations of n_end icoefficient vectors  \n",
    "picfs = list(iter.permutations(range(0,len(icoeffs_reg)),n_end))\n",
    "icfs = [ picfs[i] for i in np.random.randint(len(picfs),size = ncs)]\n",
    "\n",
    "# All permutation of combinations of n_end icoefficient vectors  \n",
    "pxcfs = list(iter.permutations(range(0,len(excoeffs_reg)),n_end))\n",
    "xcfs = [ pxcfs[i] for i in np.random.randint(len(pxcfs),size = ncs)]\n",
    "            \n",
    "# Initializing Coefficient Matrix            \n",
    "coeff = np.zeros((n_end,ncs,t_inst+n_exo))\n",
    "for j in range(n_end):\n",
    "    for i in range(ncs):\n",
    "        for k in range(n_exo):\n",
    "            coeff[j,i,k] = excoeffs_reg[xcfs[i][j]][k]\n",
    "        \n",
    "        for k in range(c_inst): \n",
    "            coeff[j,i,icr[i][k]+n_exo-1] = icoeffs_reg[icfs[i][j]][k]            \n",
    "            \n",
    "## Joint Distribution of Exogenous regressors\n",
    "# Vector of Means (=0)\n",
    "mu_ex = np.zeros(n_exo)\n",
    "# Diagonal matrix of variaces (=1)\n",
    "var_ex = np.eye(n_exo)\n",
    "# Variance Covariance Matrix Generation or EACH crossection\n",
    "for i in np.arange(len(ex_vpro)):\n",
    "    var_ex = (var_ex + ex_vpro[i]*np.eye(n_exo,k=i+1)\n",
    "                         + ex_vpro[i]*np.eye(n_exo,k=-(i+1))) \n",
    "# Exogenous regressor mean vector for ALL Crossections\n",
    "Mu_ex = np.tile(mu_ex,ncs) \n",
    "# Exogenous regressor variance covariance matrix for ALL Crossections\n",
    "V_ex = blkdiag(var_ex,ncs)\n",
    "    \n",
    "## Joint Distribution of Instruments for all cross sections\n",
    "# Vector of Means (=0)\n",
    "mu_inst = np.zeros(t_inst)\n",
    "# Diagonal Matrix of Variaces (=1)\n",
    "var_inst = np.eye(t_inst)\n",
    "# Variance Covariance Matrix Generation\n",
    "for i in np.arange(len(inst_vpro)):\n",
    "    var_inst = (var_inst + inst_vpro[i]*np.eye(t_inst,k=i+1) \n",
    "                         + inst_vpro[i]*np.eye(t_inst,k=-(i+1)))\n",
    "    \n",
    "## Joint Distribution of Error Terms for EACH crossection\n",
    "# Vector of means\n",
    "mu_err = np.zeros(n_end+1)\n",
    "# Diagonal Matrix of Variances \n",
    "var_err = np.eye(n_end+1)\n",
    "# Variance Covariance Matrix Generation\n",
    "if frc == 0 : \n",
    "    # Var Cov matrix for correlated errors ==> additive linear control functions \n",
    "    for i in np.arange(len(err_vpro)):\n",
    "        var_err = (var_err + err_vpro[i]*np.eye(n_end+1,k=i+1) \n",
    "                             + err_vpro[i]*np.eye(n_end+1,k=-(i+1)))\n",
    "# Error term mean vector for ALL Crossections\n",
    "Mu_err = np.tile(mu_err,ncs)        \n",
    "# Error term variance covariance matrix for ALL Crossections\n",
    "V_err = blkdiag(var_err,ncs)\n",
    "\n",
    "## Variable Generation\n",
    "# Exogenous Regressor Generation\n",
    "Ex = np.random.multivariate_normal(Mu_ex,V_ex,ntp)\n",
    "# Instruments Generation\n",
    "Inst = np.random.multivariate_normal(mu_inst,var_inst,ntp)\n",
    "# Error Terms Generation \n",
    "Err = np.random.multivariate_normal(Mu_err,V_err,ntp)\n",
    "\n",
    "## Variable Name Generation\n",
    "ex_nms = [''.join(['Z2',str(i),',',str(j)]) for i in list(range(1,ncs+1)) for j in list(range(1,n_exo+1))]\n",
    "\n",
    "# Constructing names for instruments\n",
    "inst_nms = [''.join(['W',str(i)]) for i in list(range(1,t_inst+1))]\n",
    "\n",
    "# Constructing names for error terms\n",
    "err_nm1 = ['e' if val == n_end+1 else 'V' for val in  list(range(1,n_end+2))*ncs]\n",
    "err_nm2 = [ str(i) for y in range(1,n_end+2) for i in iter.repeat(y,n_end+1)]\n",
    "err_nm3 = ['' if val == n_end+1 else ''.join([',',str(val)]) for val in list(range(1,n_end+2))*ncs]\n",
    "err_nm  = [''.join([err_nm1[i],err_nm2[i],err_nm3[i]]) for i in range(len(err_nm1))]\n",
    "\n",
    "## Optional Data Frame Generation \n",
    "Ex_df = pd.DataFrame(Ex,columns = ex_nms)\n",
    "Inst_df = pd.DataFrame(Inst, columns = inst_nms)\n",
    "Err_df = pd.DataFrame(Err,columns = err_nm)\n",
    "\n",
    "## Generating Endogenous (primary) regressors\n",
    "for j in range(n_end):\n",
    "    for i in range(ncs):\n",
    "        # Regular expression for the relevant exogenous regressors\n",
    "        ex_pat = ''.join(['^Z2',str(i+1)])\n",
    "        # Regular expression for the relevant error term. \n",
    "        err_pat = ''.join(['V',str(i+1),',',str(j+1)])\n",
    "        # Extracting exog regresors converting to numpy array\n",
    "        pe1 = pd.concat([Ex_df.filter(regex = ex_pat),Inst_df], axis = 1).values\n",
    "        # Extracting error variable and converting to numpy array\n",
    "        pe2 = Err_df.filter(regex = err_pat).values\n",
    "        # Calculating the endogenous primary regressor\n",
    "        pe = pe1.dot(coeff[j,i,:]).reshape(pe1.shape[0],1) + pe2\n",
    "        # Constructing the appropriate name for the endo regressor\n",
    "        end_nm = ''.join(['Z1',str(i+1),',',str(j+1)])\n",
    "        if j == 0 and i == 0:\n",
    "            # Initializing the endog df with first calculated regressor\n",
    "            End_df = pd.DataFrame(pe,columns = [end_nm])\n",
    "        else:\n",
    "            # Adding calculated endog regressor onto df\n",
    "            End_df[end_nm] = pe\n",
    "\n",
    "# Common Primary Coeff Vector\n",
    "p_commoncf = np.array(([1,-1]*10)[:n_end+n_exo]).reshape(n_end+n_exo,1)\n",
    "# Fixed Effect for each crossection\n",
    "fe = [ 1+x/2 for x in np.arange(0,ncs)]\n",
    "\n",
    "## Generation of primary regressand\n",
    "for i in range(ncs):\n",
    "    # Regular expression for the relevant endogenous regressors\n",
    "    en_pat = ''.join(['^Z1',str(i+1)])\n",
    "    # Regular expression for the relevant exogenous regressors\n",
    "    ex_pat = ''.join(['^Z2',str(i+1)])\n",
    "    # Name of apporpriate primary error term\n",
    "    er_nm = ''.join(['e',str(i+1)])\n",
    "    # Extracting appropriate regressor for primary equation\n",
    "    pr3 = pd.concat([End_df.filter(regex = en_pat),Ex_df.filter(regex = ex_pat)], axis = 1).values\n",
    "    # Extracting appropriate error term\n",
    "    pr4 = Err_df[er_nm].values.reshape(Err_df.shape[0],1)\n",
    "    # Generating primary regressand\n",
    "    pr = fe[i] + pr3.dot(p_commoncf)+pr4\n",
    "    # Constructing the appropriate name for the endo regressor\n",
    "    pr_nm = ''.join(['Y',str(i+1)])\n",
    "    if i == 0:\n",
    "        # Initializing the regressand df \n",
    "        Pr_df = pd.DataFrame(pr,columns = [pr_nm])\n",
    "    else:\n",
    "        # Adding generated regressand to df\n",
    "        Pr_df[pr_nm] = pr\n",
    "\n",
    "# Constructing full data frame\n",
    "Full_df = pd.concat([Pr_df,End_df],axis = 1) \n",
    "Full_df = pd.concat([Full_df,Ex_df],axis = 1)\n",
    "Full_df = pd.concat([Full_df,Inst_df],axis = 1)\n",
    "\n",
    "## Converting Data To Long Panel Type\n",
    "for i in range(ncs):\n",
    "    # Initializing temporary df\n",
    "    pL = None\n",
    "    # Columns Names for endogeneous regressors\n",
    "    Z1_nm = [ ''.join(['Z1',',',str(j)]) for j in range(1,n_end+1)]\n",
    "    # Columns Names for exogenous regressors\n",
    "    Z2_nm = [ ''.join(['Z2',',',str(j)]) for j in range(1,n_end+1)]\n",
    "    # Adding regressand columns to pL\n",
    "    pL = pd.DataFrame(Full_df[''.join(['Y',str(i+1)])].values,columns = ['Y'])\n",
    "    # Adding endog regressors to pL\n",
    "    pL = pd.concat([pL,pd.DataFrame(Full_df.filter(regex = ''.join(['^Z1',str(i+1)])).values\n",
    "                                    ,columns = Z1_nm)],axis = 1)\n",
    "    # Adding exog regressors to pL\n",
    "    pL = pd.concat([pL,pd.DataFrame(Full_df.filter(regex = ''.join(['^Z2',str(i+1)])).values\n",
    "                                    ,columns = Z2_nm)],axis = 1)\n",
    "    # Adding the crossection variable\n",
    "    pL['crs'] = i+1\n",
    "    # Adding the time component variable\n",
    "    pL['t'] = pd.DataFrame(np.arange(1,ntp+1).reshape(ntp,1))\n",
    "    if i == 0 :\n",
    "        # Initializing Data_long\n",
    "        Data_long = pL\n",
    "    else:\n",
    "        # Adding pL to the bottom of Data_long\n",
    "        Data_long = pd.concat([Data_long,pL], axis = 0)\n",
    "\n",
    "# Sorting Data_long by column name      \n",
    "Data_long = Data_long[list(Data_long.columns)[-2:] + list(Data_long.columns)[:-2]]\n",
    "\n",
    "# Names for export data sets\n",
    "Dlng_nms = list(Data_long.columns)\n",
    "Dins_nms = list(Inst_df.columns)\n",
    "Derr_nms = list(Err_df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['crs', 't', 'Y', 'Z1,1', 'Z1,2', 'Z2,1', 'Z2,2'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_long.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crs', 't', 'Y', 'Z1,1', 'Z1,2', 'Z2,1', 'Z2,2']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dlng_nms = list(Data_long.columns)\n",
    "Dins_nms = list(Inst_df.columns)\n",
    "Derr_nms = list(Err_df.columns)\n",
    "Dl_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W1', 'W2', 'W3', 'W4', 'W5', 'W6', 'W7', 'W8', 'W9', 'W10']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dins_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V1,1', 'V1,2', 'e1', 'V2,1', 'V2,2', 'e2', 'V3,1', 'V3,2', 'e3']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Derr_nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
