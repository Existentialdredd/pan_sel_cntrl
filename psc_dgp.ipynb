{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preamble: Package Loading\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import itertools as iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Block Diagonal Matrix Function </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blkdiag(mat,nb):\n",
    "    \"\"\"\n",
    "INPUTS\n",
    "mat     Square Matrix which will form the block in a block diagonal matrix\n",
    "nb      Number of diagonal block in output matrix \n",
    "\n",
    "OUTPUT\n",
    "v       Block diagonal matrix of dimension ( nb*mat.shape[0] x nb*mat.shape[0] )\n",
    "    \"\"\"\n",
    "    # Initializing the varcov matrix for all crosssections\n",
    "    v = np.hstack((mat,np.zeros((mat.shape[0],(nb-1)*(mat.shape[1])))))\n",
    "    # Registry matrix used in following loops\n",
    "    vreg = np.eye(nb-1)\n",
    "    for j in np.arange(nb-1):\n",
    "        # Initializing current block of rows \n",
    "        pv = np.zeros((mat.shape[0],mat.shape[0]))\n",
    "        # Horiz Stacking either zeros or var_err depending on ve_reg[j,i]\n",
    "        for i in np.arange(nb-1):\n",
    "            if vreg[j,i] == 1: # Stack var_err onto pv_err\n",
    "                pv = np.hstack((pv,mat))\n",
    "            if vreg[j,i] == 0: # Stack zeros onto pv_err\n",
    "                pv = np.hstack((pv,np.zeros((mat.shape[0],mat.shape[0]))))\n",
    "        # Vertically stacking block rows on top of one another\n",
    "        v = np.vstack((v,pv))\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Block Diagonal Matrix Function Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blkdiag(np.ones((3,3)),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> DGP Inputs </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setting a Seed\n",
    "np.random.seed([10])\n",
    "\n",
    "# Number of Time Periods\n",
    "ntp = 10\n",
    "# Number of Cross-Sections\n",
    "ncs = 3\n",
    "# Number of Endogenous Variables in Primary Equation\n",
    "n_end = 2\n",
    "# Number of Endogenous Variables in Primary Equation\n",
    "n_exo = 2\n",
    "# Total Number of Instruments\n",
    "t_inst = 10\n",
    "# Number of Instruments per Crossection\n",
    "c_inst = 3\n",
    "# Indicator for whether to force additive non linear cntrl function. 1 = yes \n",
    "frc = 0\n",
    "\n",
    "# Vector of exog off diagonal covariances i.e. cov(Z2t_l,Z2t_(l+j)) = ex_vpro[j-1]\n",
    "ex_vpro = [0.5]\n",
    "# Vector of inst off diagonal covariances i.e. cov(Wt_l,Wt_(l+j)) = inst_vpro[j-1]\n",
    "inst_vpro = [0.8 , 0.6 , 0.4, 0.2]\n",
    "# Vector of error off diagonal covariances i.e. cov(Wt_l,Wt_(l+j)) = inst_vpro[j-1]\n",
    "err_vpro = [0.8 , 0.6 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> DGP Generation Code </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Collection of all Coefficients on Instruments \n",
    "icoeffs_reg = list(iter.product([-1,1],repeat = c_inst))\n",
    "# Collection of all Coefficients on Exogenous Variables\n",
    "excoeffs_reg = list(iter.product([-1,1],repeat = n_exo))\n",
    "# Registry of instrument assignments\n",
    "insts_reg = list(iter.combinations(np.arange(1,t_inst+1),c_inst))\n",
    "# Iterator for instrument coefficients\n",
    "lpw_iter = [(x,y) for y in np.arange(1,len(coeff)+1) for x in np.arange(1,len(insts)+1)]\n",
    "# Iterator for exogenous variables coefficients\n",
    "lpz_iter = []\n",
    "for x in np.arange(1,np.ceil(ncs/4)+1): \n",
    "    for y in [0,1,2,3] : lpz_iter.append(y)\n",
    "\n",
    "# Initializing the full coefficient matrix\n",
    "coeffs = np.zeros((ncs,n_exo+t_inst))\n",
    "\n",
    "# Generating coefficients matrix\n",
    "for i in np.arange(ncs): \n",
    "    # List of which instruments (col #'s) are used for crossection i\n",
    "    cr = insts_reg[np.random.randint(len(insts_reg))]\n",
    "    # List of coefficients which correspond to those instruments\n",
    "    cfs = icoeffs_reg[np.random.randint(len(icoeffs_reg))]\n",
    "    for j in np.arange(n_exo):\n",
    "        # Setting the coeff for each exogenous regression\n",
    "        coeffs[i,j] = excoeffs_reg[lpz_iter[i]][j]\n",
    "    for j in np.arange(c_nist):\n",
    "        # Setting the coeff for each instrument used by i\n",
    "        coeffs[i,n_exo-1+cr[j]] = cfs[j]\n",
    "            \n",
    "## Joint Distribution of Exogenous regressors\n",
    "# Vector of Means (=0)\n",
    "mu_ex = np.zeros(n_exo)\n",
    "# Diagonal matrix of variaces (=1)\n",
    "var_ex = np.eye(n_exo)\n",
    "# Variance Covariance Matrix Generation or EACH crossection\n",
    "for i in np.arange(len(ex_vpro)):\n",
    "    var_ex = (var_ex + ex_vpro[i]*np.eye(n_exo,k=i+1)\n",
    "                         + ex_vpro[i]*np.eye(n_exo,k=-(i+1))) \n",
    "# Exogenous regressor mean vector for ALL Crossections\n",
    "Mu_ex = np.tile(mu_ex,ncs) \n",
    "# Exogenous regressor variance covariance matrix for ALL Crossections\n",
    "V_ex = blkdiag(var_ex,ncs)\n",
    "    \n",
    "## Joint Distribution of Instruments for all cross sections\n",
    "# Vector of Means (=0)\n",
    "mu_inst = np.zeros(c_inst)\n",
    "# Diagonal Matrix of Variaces (=1)\n",
    "var_inst = np.eye(t_inst)\n",
    "# Variance Covariance Matrix Generation\n",
    "for i in np.arange(len(inst_vpro)):\n",
    "    var_inst = (var_inst + inst_vpro[i]*np.eye(t_inst,k=i+1) \n",
    "                         + inst_vpro[i]*np.eye(t_inst,k=-(i+1)))\n",
    "    \n",
    "## Joint Distribution of Error Terms for EACH crossection\n",
    "# Vector of means\n",
    "mu_err = np.zeros(n_end+1)\n",
    "# Diagonal Matrix of Variances \n",
    "var_err = np.eye(n_end+1)\n",
    "# Variance Covariance Matrix Generation\n",
    "if frc == 0 : \n",
    "    # Var Cov matrix for correlated errors ==> additive linear control functions \n",
    "    for i in np.arange(len(err_vpro)):\n",
    "        var_err = (var_err + err_vpro[i]*np.eye(n_end+1,k=i+1) \n",
    "                             + err_vpro[i]*np.eye(n_end+1,k=-(i+1)))\n",
    "# Error term mean vector for ALL Crossections\n",
    "Mu_err = np.tile(mu_err,ncs)        \n",
    "# Error term variance covariance matrix for ALL Crossections\n",
    "V_err = blkdiag(var_err,ncs)\n",
    "\n",
    "# Exogenous Regressor Generation\n",
    "Ex = np.random.multivariate_normal(Mu_ex,V_ex,ntp)\n",
    "\n",
    "# \n",
    "Inst = np.random.multivariate_normal(mu_inst,var_inst,ntp)\n",
    "\n",
    "#\n",
    "Err = np.random.multivariate_normal(Mu_err,V_err,ntp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [-1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0., -1.],\n",
       "       [ 1., -1.,  1.,  0.,  0.,  1.,  0.,  0.,  0., -1.,  0.,  0.]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  0.8,  0.6,  0.4,  0.2,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0.8,  1. ,  0.8,  0.6,  0.4,  0.2,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0.6,  0.8,  1. ,  0.8,  0.6,  0.4,  0.2,  0. ,  0. ,  0. ],\n",
       "       [ 0.4,  0.6,  0.8,  1. ,  0.8,  0.6,  0.4,  0.2,  0. ,  0. ],\n",
       "       [ 0.2,  0.4,  0.6,  0.8,  1. ,  0.8,  0.6,  0.4,  0.2,  0. ],\n",
       "       [ 0. ,  0.2,  0.4,  0.6,  0.8,  1. ,  0.8,  0.6,  0.4,  0.2],\n",
       "       [ 0. ,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ,  0.8,  0.6,  0.4],\n",
       "       [ 0. ,  0. ,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ,  0.8,  0.6],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ,  0.8],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  0.5,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0.5,  1. ,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  1. ,  0.5,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0.5,  1. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  1. ,  0.5],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0.5,  1. ]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  0.8,  0.6,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0.8,  1. ,  0.8,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0.6,  0.8,  1. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  1. ,  0.8,  0.6,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0.8,  1. ,  0.8,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0.6,  0.8,  1. ,  0. ,  0. ,  0. ],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  1. ,  0.8,  0.6],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0.8,  1. ,  0.8],\n",
       "       [ 0. ,  0. ,  0. ,  0. ,  0. ,  0. ,  0.6,  0.8,  1. ]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
